{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 5.253940455341506,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.08756567425569177,
      "grad_norm": 0.38542935252189636,
      "learning_rate": 5e-06,
      "loss": 4.5504,
      "step": 50
    },
    {
      "epoch": 0.17513134851138354,
      "grad_norm": 0.44302353262901306,
      "learning_rate": 1e-05,
      "loss": 4.4692,
      "step": 100
    },
    {
      "epoch": 0.2626970227670753,
      "grad_norm": 0.3924195468425751,
      "learning_rate": 1.5e-05,
      "loss": 4.4152,
      "step": 150
    },
    {
      "epoch": 0.3502626970227671,
      "grad_norm": 0.3584044575691223,
      "learning_rate": 2e-05,
      "loss": 4.3499,
      "step": 200
    },
    {
      "epoch": 0.43782837127845886,
      "grad_norm": 0.4086325764656067,
      "learning_rate": 2.5e-05,
      "loss": 4.2708,
      "step": 250
    },
    {
      "epoch": 0.5253940455341506,
      "grad_norm": 0.40994635224342346,
      "learning_rate": 3e-05,
      "loss": 4.2499,
      "step": 300
    },
    {
      "epoch": 0.6129597197898424,
      "grad_norm": 0.43909332156181335,
      "learning_rate": 3.5e-05,
      "loss": 4.2445,
      "step": 350
    },
    {
      "epoch": 0.7005253940455342,
      "grad_norm": 0.49785900115966797,
      "learning_rate": 4e-05,
      "loss": 4.2208,
      "step": 400
    },
    {
      "epoch": 0.7880910683012259,
      "grad_norm": 0.4873664677143097,
      "learning_rate": 4.5e-05,
      "loss": 4.1937,
      "step": 450
    },
    {
      "epoch": 0.8756567425569177,
      "grad_norm": 0.509265124797821,
      "learning_rate": 5e-05,
      "loss": 4.1639,
      "step": 500
    },
    {
      "epoch": 0.9632224168126094,
      "grad_norm": 0.5850520730018616,
      "learning_rate": 4.914559125085441e-05,
      "loss": 4.1504,
      "step": 550
    },
    {
      "epoch": 1.0507880910683012,
      "grad_norm": 0.5384153723716736,
      "learning_rate": 4.829118250170882e-05,
      "loss": 4.1582,
      "step": 600
    },
    {
      "epoch": 1.138353765323993,
      "grad_norm": 0.5984302163124084,
      "learning_rate": 4.7436773752563226e-05,
      "loss": 4.1472,
      "step": 650
    },
    {
      "epoch": 1.2259194395796849,
      "grad_norm": 0.5783395171165466,
      "learning_rate": 4.6582365003417636e-05,
      "loss": 4.1395,
      "step": 700
    },
    {
      "epoch": 1.3134851138353765,
      "grad_norm": 0.539943516254425,
      "learning_rate": 4.5727956254272047e-05,
      "loss": 4.178,
      "step": 750
    },
    {
      "epoch": 1.4010507880910683,
      "grad_norm": 0.5637712478637695,
      "learning_rate": 4.487354750512646e-05,
      "loss": 4.1438,
      "step": 800
    },
    {
      "epoch": 1.4886164623467601,
      "grad_norm": 0.636740505695343,
      "learning_rate": 4.401913875598087e-05,
      "loss": 4.148,
      "step": 850
    },
    {
      "epoch": 1.5761821366024518,
      "grad_norm": 0.6238742470741272,
      "learning_rate": 4.316473000683528e-05,
      "loss": 4.1774,
      "step": 900
    },
    {
      "epoch": 1.6637478108581436,
      "grad_norm": 0.5774322748184204,
      "learning_rate": 4.231032125768968e-05,
      "loss": 4.1465,
      "step": 950
    },
    {
      "epoch": 1.7513134851138354,
      "grad_norm": 0.5881403684616089,
      "learning_rate": 4.1455912508544084e-05,
      "loss": 4.1198,
      "step": 1000
    },
    {
      "epoch": 1.8388791593695273,
      "grad_norm": 0.6566855311393738,
      "learning_rate": 4.0601503759398494e-05,
      "loss": 4.1049,
      "step": 1050
    },
    {
      "epoch": 1.926444833625219,
      "grad_norm": 0.5915064215660095,
      "learning_rate": 3.9747095010252904e-05,
      "loss": 4.1205,
      "step": 1100
    },
    {
      "epoch": 2.0140105078809105,
      "grad_norm": 0.6416226625442505,
      "learning_rate": 3.8892686261107314e-05,
      "loss": 4.1751,
      "step": 1150
    },
    {
      "epoch": 2.1015761821366024,
      "grad_norm": 0.6738610863685608,
      "learning_rate": 3.8038277511961725e-05,
      "loss": 4.1292,
      "step": 1200
    },
    {
      "epoch": 2.189141856392294,
      "grad_norm": 0.5672829151153564,
      "learning_rate": 3.7183868762816135e-05,
      "loss": 4.1378,
      "step": 1250
    },
    {
      "epoch": 2.276707530647986,
      "grad_norm": 0.6075205206871033,
      "learning_rate": 3.632946001367054e-05,
      "loss": 4.1083,
      "step": 1300
    },
    {
      "epoch": 2.364273204903678,
      "grad_norm": 0.6446042656898499,
      "learning_rate": 3.547505126452495e-05,
      "loss": 4.1372,
      "step": 1350
    },
    {
      "epoch": 2.4518388791593697,
      "grad_norm": 0.6107620000839233,
      "learning_rate": 3.462064251537936e-05,
      "loss": 4.086,
      "step": 1400
    },
    {
      "epoch": 2.5394045534150615,
      "grad_norm": 0.6242852210998535,
      "learning_rate": 3.376623376623377e-05,
      "loss": 4.1455,
      "step": 1450
    },
    {
      "epoch": 2.626970227670753,
      "grad_norm": 0.6401075124740601,
      "learning_rate": 3.291182501708818e-05,
      "loss": 4.0776,
      "step": 1500
    },
    {
      "epoch": 2.714535901926445,
      "grad_norm": 0.6192626953125,
      "learning_rate": 3.205741626794259e-05,
      "loss": 4.0827,
      "step": 1550
    },
    {
      "epoch": 2.8021015761821366,
      "grad_norm": 0.7148258090019226,
      "learning_rate": 3.120300751879699e-05,
      "loss": 4.1109,
      "step": 1600
    },
    {
      "epoch": 2.8896672504378285,
      "grad_norm": 0.6382743716239929,
      "learning_rate": 3.0348598769651403e-05,
      "loss": 4.0995,
      "step": 1650
    },
    {
      "epoch": 2.9772329246935203,
      "grad_norm": 0.6922718286514282,
      "learning_rate": 2.9494190020505813e-05,
      "loss": 4.115,
      "step": 1700
    },
    {
      "epoch": 3.0647985989492117,
      "grad_norm": 0.7057119607925415,
      "learning_rate": 2.8639781271360223e-05,
      "loss": 4.0656,
      "step": 1750
    },
    {
      "epoch": 3.1523642732049035,
      "grad_norm": 0.7357406616210938,
      "learning_rate": 2.778537252221463e-05,
      "loss": 4.0871,
      "step": 1800
    },
    {
      "epoch": 3.2399299474605954,
      "grad_norm": 0.6828047633171082,
      "learning_rate": 2.693096377306904e-05,
      "loss": 4.1286,
      "step": 1850
    },
    {
      "epoch": 3.327495621716287,
      "grad_norm": 0.6689919233322144,
      "learning_rate": 2.6076555023923443e-05,
      "loss": 4.106,
      "step": 1900
    },
    {
      "epoch": 3.415061295971979,
      "grad_norm": 0.6209766268730164,
      "learning_rate": 2.5222146274777853e-05,
      "loss": 4.093,
      "step": 1950
    },
    {
      "epoch": 3.502626970227671,
      "grad_norm": 0.7330661416053772,
      "learning_rate": 2.4367737525632264e-05,
      "loss": 4.0798,
      "step": 2000
    },
    {
      "epoch": 3.5901926444833627,
      "grad_norm": 0.6821293830871582,
      "learning_rate": 2.3513328776486674e-05,
      "loss": 4.1224,
      "step": 2050
    },
    {
      "epoch": 3.6777583187390546,
      "grad_norm": 0.7407291531562805,
      "learning_rate": 2.2658920027341084e-05,
      "loss": 4.0899,
      "step": 2100
    },
    {
      "epoch": 3.765323992994746,
      "grad_norm": 0.6742636561393738,
      "learning_rate": 2.1804511278195487e-05,
      "loss": 4.089,
      "step": 2150
    },
    {
      "epoch": 3.852889667250438,
      "grad_norm": 0.7288089394569397,
      "learning_rate": 2.0950102529049898e-05,
      "loss": 4.0955,
      "step": 2200
    },
    {
      "epoch": 3.9404553415061296,
      "grad_norm": 0.6800920367240906,
      "learning_rate": 2.0095693779904308e-05,
      "loss": 4.0895,
      "step": 2250
    },
    {
      "epoch": 4.028021015761821,
      "grad_norm": 0.7047513127326965,
      "learning_rate": 1.9241285030758715e-05,
      "loss": 4.0703,
      "step": 2300
    },
    {
      "epoch": 4.115586690017513,
      "grad_norm": 0.714402437210083,
      "learning_rate": 1.8386876281613125e-05,
      "loss": 4.0697,
      "step": 2350
    },
    {
      "epoch": 4.203152364273205,
      "grad_norm": 0.805176854133606,
      "learning_rate": 1.7532467532467535e-05,
      "loss": 4.0968,
      "step": 2400
    },
    {
      "epoch": 4.2907180385288965,
      "grad_norm": 0.6906054615974426,
      "learning_rate": 1.667805878332194e-05,
      "loss": 4.1056,
      "step": 2450
    },
    {
      "epoch": 4.378283712784588,
      "grad_norm": 0.7455549836158752,
      "learning_rate": 1.5823650034176352e-05,
      "loss": 4.0758,
      "step": 2500
    },
    {
      "epoch": 4.46584938704028,
      "grad_norm": 0.7587936520576477,
      "learning_rate": 1.496924128503076e-05,
      "loss": 4.0783,
      "step": 2550
    },
    {
      "epoch": 4.553415061295972,
      "grad_norm": 0.6939588785171509,
      "learning_rate": 1.4114832535885167e-05,
      "loss": 4.0886,
      "step": 2600
    },
    {
      "epoch": 4.640980735551664,
      "grad_norm": 0.6968708634376526,
      "learning_rate": 1.3260423786739576e-05,
      "loss": 4.1058,
      "step": 2650
    },
    {
      "epoch": 4.728546409807356,
      "grad_norm": 0.7668875455856323,
      "learning_rate": 1.2406015037593984e-05,
      "loss": 4.1133,
      "step": 2700
    },
    {
      "epoch": 4.816112084063048,
      "grad_norm": 0.7097353339195251,
      "learning_rate": 1.1551606288448394e-05,
      "loss": 4.0607,
      "step": 2750
    },
    {
      "epoch": 4.903677758318739,
      "grad_norm": 0.6303295493125916,
      "learning_rate": 1.0697197539302803e-05,
      "loss": 4.064,
      "step": 2800
    },
    {
      "epoch": 4.99124343257443,
      "grad_norm": 0.6774030923843384,
      "learning_rate": 9.842788790157211e-06,
      "loss": 4.059,
      "step": 2850
    },
    {
      "epoch": 5.078809106830122,
      "grad_norm": 0.7304373979568481,
      "learning_rate": 8.988380041011621e-06,
      "loss": 4.061,
      "step": 2900
    },
    {
      "epoch": 5.166374781085814,
      "grad_norm": 0.7257652282714844,
      "learning_rate": 8.133971291866028e-06,
      "loss": 4.0812,
      "step": 2950
    },
    {
      "epoch": 5.253940455341506,
      "grad_norm": 0.7114819288253784,
      "learning_rate": 7.2795625427204375e-06,
      "loss": 4.065,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3426,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 6,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.0470589760274432e+17,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
